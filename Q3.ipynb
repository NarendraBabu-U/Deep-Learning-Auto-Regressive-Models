{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#          01234567\n",
    "symbols = \"EBabcdXY\"\n",
    "symbols_onehot = np.array([[1,0,0,0,0,0,0,0],\n",
    "                           [0,1,0,0,0,0,0,0],\n",
    "                           [0,0,1,0,0,0,0,0],\n",
    "                           [0,0,0,1,0,0,0,0],\n",
    "                           [0,0,0,0,1,0,0,0],\n",
    "                           [0,0,0,0,0,1,0,0],\n",
    "                           [0,0,0,0,0,0,1,0],\n",
    "                           [0,0,0,0,0,0,0,1]\n",
    "                          ])\n",
    "\n",
    "#              01234567\n",
    "classlabels = 'QRSUVABC'\n",
    "\n",
    "classlabels_onehot = np.array([[1,0,0,0,0,0,0,0],\n",
    "                               [0,1,0,0,0,0,0,0],\n",
    "                               [0,0,1,0,0,0,0,0],\n",
    "                               [0,0,0,1,0,0,0,0],\n",
    "                               [0,0,0,0,1,0,0,0],\n",
    "                               [0,0,0,0,0,1,0,0],\n",
    "                               [0,0,0,0,0,0,1,0],\n",
    "                               [0,0,0,0,0,0,0,1]\n",
    "                              ])\n",
    "\n",
    "#                            Q       R       S       U       V       A       B      C\n",
    "classidx2rule = np.array([[6,6,6],[6,6,7],[6,7,6],[6,7,7],[7,6,6],[7,6,7],[7,7,6],[7,7,7]\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence():\n",
    "    seq_length = np.random.choice(range(100, 110))\n",
    "    t1 = np.random.choice(range(10,21))\n",
    "    t2 = np.random.choice(range(33,44))\n",
    "    t3 = np.random.choice(range(66,76)) \n",
    "    targetclassidx = np.random.choice(range(0,8)) #randomly choose a target class\n",
    "    \n",
    "    tagetclass_onehot = classlabels_onehot[targetclassidx]\n",
    "    \n",
    "    seq = np.zeros((seq_length,1),dtype=\"int\")\n",
    "    seq[0] = 0 #first char is E\n",
    "    seq[-1] = 1 #last char is B\n",
    "    \n",
    "    #randomly asaign abcd to the rest of the positions\n",
    "    for i in range(1,seq_length):\n",
    "        seq[i] = np.random.choice([2,3,4,5])\n",
    "\n",
    "    # insert X,Y values based on class\n",
    "    seq[t1], seq[t2], seq[t3] = classidx2rule[targetclassidx]\n",
    "    \n",
    "    #generate onehot for sequence\n",
    "    seq_onehot = np.zeros((seq_length,8))\n",
    "    for idx in range(seq_length):\n",
    "        seq_onehot[idx] = symbols_onehot[seq[idx]]\n",
    "        \n",
    "    return seq_length, seq, seq_onehot, targetclassidx, tagetclass_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mylstm(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Mylstm, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size = 8, hidden_size = 2)\n",
    "        self.lstm2 = nn.LSTM(input_size = 2, hidden_size = 4)\n",
    "        self.lstm3 = nn.LSTM(input_size = 4, hidden_size = 8)       \n",
    "        self.linear = nn.Linear(in_features=8, out_features=8)\n",
    "        \n",
    "    def forward(self, input):\n",
    "       \n",
    "        lstm_out1, (self.h1, self.c1) = self.lstm1(input,(self.h1, self.c1))\n",
    "        lstm_out2, (self.h2, self.c2) = self.lstm2(self.h1,(self.h2, self.c2))\n",
    "        lstm_out3, (self.h3, self.c3) = self.lstm3(self.h2,(self.h3, self.c3))\n",
    "           \n",
    "        #pred_vec = lstm_out3[-1]\n",
    "        pred_vec = self.linear(lstm_out3[-1])\n",
    "            \n",
    "        return pred_vec\n",
    "    \n",
    "    def reset_hidden_states(self):\n",
    "        (self.h1, self.c1) = (torch.zeros(1, 1, 2), torch.zeros(1, 1, 2))\n",
    "        (self.h2, self.c2) = (torch.zeros(1, 1, 4), torch.zeros(1, 1, 4))\n",
    "        (self.h3, self.c3) = (torch.zeros(1, 1, 8), torch.zeros(1, 1, 8))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "0 tensor(2.2155, grad_fn=<NllLossBackward>) tensor([[ 0.3342,  0.1350, -0.1180, -0.0754,  0.1484, -0.3705, -0.1703, -0.1468]],\n",
      "       grad_fn=<AddmmBackward>) tensor([0.3342]) tensor([0]) tensor([7]) 0\n",
      "------------------------------------------------------\n",
      "5000 tensor(1.9009, grad_fn=<NllLossBackward>) tensor([[-0.7544, -1.0631, -0.3845, -0.8196, -1.0744,  0.2158, -0.5402, -0.3275]],\n",
      "       grad_fn=<AddmmBackward>) tensor([0.2158]) tensor([5]) tensor([7]) 638\n",
      "------------------------------------------------------\n",
      "10000 tensor(1.6744, grad_fn=<NllLossBackward>) tensor([[-0.5463, -1.4807, -0.1209, -0.5776, -0.5334, -0.9159, -0.7002, -0.0089]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.0089]) tensor([7]) tensor([2]) 625\n",
      "------------------------------------------------------\n",
      "15000 tensor(1.8432, grad_fn=<NllLossBackward>) tensor([[-0.8450, -1.2946, -0.5807, -0.3312, -0.3303, -0.3103, -0.5295, -0.6585]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.3103]) tensor([5]) tensor([4]) 638\n",
      "------------------------------------------------------\n",
      "20000 tensor(2.0425, grad_fn=<NllLossBackward>) tensor([[-0.4928,  0.0387, -0.3163, -0.4966, -0.8211, -1.2182, -0.5004, -1.0660]],\n",
      "       grad_fn=<AddmmBackward>) tensor([0.0387]) tensor([1]) tensor([6]) 651\n",
      "------------------------------------------------------\n",
      "25000 tensor(1.9955, grad_fn=<NllLossBackward>) tensor([[-0.6757, -0.5271, -0.4252, -0.9288, -0.3491, -0.6704, -0.6473, -0.7892]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.3491]) tensor([4]) tensor([1]) 601\n",
      "------------------------------------------------------\n",
      "30000 tensor(2.2349, grad_fn=<NllLossBackward>) tensor([[-0.6172, -0.8684, -0.0191, -0.7181, -1.0034, -0.8362, -0.0791, -0.9016]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.0191]) tensor([2]) tensor([3]) 600\n",
      "------------------------------------------------------\n",
      "35000 tensor(2.1040, grad_fn=<NllLossBackward>) tensor([[-0.5037, -0.7157, -1.4916, -0.5128, -0.4216, -0.2074, -0.6270, -0.6078]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.2074]) tensor([5]) tensor([7]) 612\n",
      "------------------------------------------------------\n",
      "40000 tensor(2.8159, grad_fn=<NllLossBackward>) tensor([[-0.8377, -0.2661, -0.5013, -0.2101, -0.4732, -1.2642, -0.0124, -1.5555]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.0124]) tensor([6]) tensor([5]) 636\n",
      "------------------------------------------------------\n",
      "45000 tensor(2.1414, grad_fn=<NllLossBackward>) tensor([[-0.6306, -0.5055, -0.9189, -0.9924, -1.2764, -0.2925, -0.1449, -0.3082]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.1449]) tensor([6]) tensor([0]) 633\n",
      "------------------------------------------------------\n",
      "50000 tensor(1.8922, grad_fn=<NllLossBackward>) tensor([[-1.3329, -0.4138, -0.5961, -0.6945, -0.7738, -0.3347, -0.2808, -0.7369]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.2808]) tensor([6]) tensor([1]) 650\n",
      "------------------------------------------------------\n",
      "55000 tensor(2.2945, grad_fn=<NllLossBackward>) tensor([[-0.8486, -0.4746, -0.8204, -0.3996, -0.4613, -0.6802, -0.9051, -0.6104]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.3996]) tensor([3]) tensor([0]) 653\n",
      "------------------------------------------------------\n",
      "60000 tensor(1.7303, grad_fn=<NllLossBackward>) tensor([[-0.5163, -0.2884, -0.7144, -0.6931, -0.5355, -0.7571, -0.8469, -0.8918]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.2884]) tensor([1]) tensor([1]) 625\n",
      "------------------------------------------------------\n",
      "65000 tensor(1.8099, grad_fn=<NllLossBackward>) tensor([[-0.3534, -1.1814, -0.6406, -0.5112, -1.0089, -0.8197, -0.6888, -0.1655]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.1655]) tensor([7]) tensor([0]) 633\n",
      "------------------------------------------------------\n",
      "70000 tensor(2.0480, grad_fn=<NllLossBackward>) tensor([[-0.2932, -0.8444, -1.3840, -1.3178, -0.4684, -0.4472, -0.5796, -0.1951]],\n",
      "       grad_fn=<AddmmBackward>) tensor([-0.1951]) tensor([7]) tensor([6]) 599\n",
      "------------------------------------------------------\n",
      "75000 tensor(1.7965, grad_fn=<NllLossBackward>) tensor([[-0.5119,  0.0629, -0.9357, -1.2995, -1.1384, -0.8660, -0.5986, -0.3287]],\n",
      "       grad_fn=<AddmmBackward>) tensor([0.0629]) tensor([1]) tensor([7]) 636\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-461c0aff8575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMylstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-461c0aff8575>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetclassidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-96d3d650a60b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlstm_out1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mlstm_out2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlstm_out3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model):\n",
    "        \n",
    "    loss_fn  = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimiser = optim.Adam(model.parameters(), lr = 0.1)\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(1000000):\n",
    "        \n",
    "        model.reset_hidden_states()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            seq_length, seq, seq_onehot, targetclassidx, targetclass_onehot = generate_sequence()\n",
    "        \n",
    "            seq_onehot = torch.from_numpy(seq_onehot).float()\n",
    "        \n",
    "            seq_onehot = seq_onehot.view([seq_length,1,8])\n",
    "            \n",
    "            targetclassidx = torch.tensor([targetclassidx])\n",
    "              \n",
    "        \n",
    "        pred = model(seq_onehot)       \n",
    "               \n",
    "        loss = loss_fn(pred, targetclassidx)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predvalue, predclassidx = torch.max(pred,-1)\n",
    "                       \n",
    "            if predclassidx == targetclassidx:\n",
    "                count = count+1\n",
    "                \n",
    "            \n",
    "            if i % 5000 == 0:\n",
    "                print(\"------------------------------------------------------\")\n",
    "                print(i,loss, pred, predvalue, predclassidx, targetclassidx, count)\n",
    "                count = 0\n",
    "                    \n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimiser.step()\n",
    "        \n",
    "    return model.eval()\n",
    "\n",
    "model1 = Mylstm()\n",
    "model1 = train_model(model1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
